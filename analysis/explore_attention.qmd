---
title: "Exploratory Attention Analysis"
format: html
editor: visual
---

```{r, echo=FALSE, message=FALSE}
rm(list = ls())

library(tidyr)
library(dplyr)
library(ggplot2)
library(patchwork)
library(IRanges)

res_path <- "/net/mimer/mnt/tank/projects2/kvs_students/2025/jbo_unbiased_seq_annot/master_thesis/figures/"
```

I have ran the ESM-2 model for 100 sequences and extracted the raw and normalized attention scores for each self-attention layer. To compare the biological signal with a baseline, we also ran the model for 5 scramble sequences per biological sequence. The attention scores have been aggregated into vectors by taken the row mean or 90% quantile to obtain an attention score per position. For the scrambled sequences, we afterwards summarize the results by computing the mean, standard deviation, minimum and maximum attention per position across the 5 sequences. 

Let's read the data.

```{r}
data_path <- "/net/mimer/mnt/tank/projects2/kvs_students/2025/jbo_unbiased_seq_annot/master_thesis/data/100_small/preprocessed/"

attn_raw_mean  <- readRDS(paste(data_path, "attn_all_layers_raw_mean.rds", sep = ""))
attn_raw_q90   <- readRDS(paste(data_path, "attn_all_layers_raw_q90.rds", sep = ""))
attn_norm_mean <- readRDS(paste(data_path, "attn_all_layers_norm_mean.rds", sep = ""))
attn_norm_q90  <- readRDS(paste(data_path, "attn_all_layers_norm_q90.rds", sep = ""))
```

The format can be seen from below.

```{r}
sample_n(attn_raw_mean, size = 10)
```

## Distribution of Attention Weights

We look at the distribution between the attention weights after aggregating to 1D. We will compare the attentions for the biological sequence with the baseline, that is, the mean attention across the 5 scrambled sequences.

```{r}
plotDistAttention <- function(attn, title){
  plot <- attn |>
    select(bio_attn, scr_attn_mean) |>
    pivot_longer(cols = bio_attn:scr_attn_mean,
                 names_to = "attn_type",
                 values_to = "attn") |>
    mutate(attn_type = case_when(attn_type == "bio_attn" ~ "Biological signal",
                                 attn_type == "scr_attn_mean" ~ "Baseline signal")) |>
    ggplot(mapping = aes(x = attn_type,
                         y = attn,
                         fill = attn_type)) +
    geom_violin(alpha = 0.6) +
    geom_boxplot(width = 0.2,
                 fill = "grey80",
                 outlier.shape = 1,
                 outlier.color = scales::alpha("black", 0.4)) + 
    theme_classic() + 
    theme(legend.position = "none",
          plot.title = element_text(size = 12),
          panel.grid.major.y = element_line(color = "grey80"),
          axis.ticks.x = element_blank()) + 
    labs(x = "",
         y = "Attention",
         title = title) + 
    scale_fill_manual(values = c("#1f618d", "#1f618d"))
  
  return(plot)
}

plotDistAttention(attn_raw_mean, "Attention: Raw, Aggregation: Mean") +
plotDistAttention(attn_raw_q90, "Attention: Raw, Aggregation: Q90") +
  plot_layout(guides = "collect")
```

There seems to be a bigger difference between the distributions for the attention scores after aggregating using the 90% quantile.

The table also contains a Z-score for the attention signal (bio_attn_Z). The Z-score is a normalized biological signal calculated per position by subtracting the mean of the attention across the 5 scrambled sequences divided by the standard deviation. 

$$Z = \frac{A_{bio}-A_{\mu_{scr}}}{A_{\sigma_{scr}}}$$

The purpose of this normalization is to center the signal around 0.

```{r}
plotDistBioZ <- function(attn, title){
  plot <- attn |>
    select(bio_attn_Z) |>
    ggplot(mapping = aes(y = bio_attn_Z)) +
    geom_boxplot(fill = "grey80",
                 outlier.shape = 1,
                 outlier.color = scales::alpha("black", 0.4)) + 
    theme_classic() + 
    theme(legend.position = "none",
          plot.title = element_text(size = 12),
          panel.grid.major.y = element_line(color = "grey80"),
          axis.ticks.x = element_blank()) + 
    labs(x = "",
         y = "Attention",
         title = title)
  
  return(plot)
}

plotDistBioZ(attn_raw_mean, "Attention: Raw, Aggregation: Mean") +
plotDistBioZ(attn_raw_q90, "Attention: Raw, Aggregation: Q90")
```

## Attention Across Layers and Annotation Types

We want to look at the attention for each feature type across the different layers. I load the annotations also denoted as features.

```{r}
accessions <- read.table(file = "/net/mimer/mnt/tank/projects2/kvs_students/2025/jbo_unbiased_seq_annot/master_thesis/data/100_small/additional/UP000005640_9606_sp_100_acc.txt") |>
  dplyr::rename(accession = "V1") |>
  select(accession) |>
  pull()

features <- readRDS(file = "/net/mimer/mnt/tank/projects2/kvs_students/2025/jbo_unbiased_seq_annot/master_thesis/data/20000_large/annotations/features_sp_filtered.rds")

features <- features |>
  filter(accession %in% unlist(accessions)) |>
  mutate(across(c(category, feature_type), ~ ifelse(is.na(.), "Unannotated", .)),
         across(c(category, feature_type), ~ str_replace(., "^(.)", toupper)))

features_expand <- features |>
  rowwise() |>
  mutate(position = list(seq(start_position, end_position))) |>
  unnest(position) |>
  select(accession, position, category, feature_type, description)
```

We get the sequence length. As not all sequences have annotated positions, we can not achieve the information from the feature table. 

```{r}
seq_length <- attn_raw_mean |>
  group_by(accession) |>
  summarise(length = max(position))
```

We join the annotations and lengths with the preprocessed attention weights. 

```{r}
addFeatures <- function(attn){
  attn_expand <- left_join(attn,
                           seq_length,
                           by = "accession",
                           relationship = "many-to-one")
  attn_expand <- left_join(attn_expand,
                           features_expand,
                           by = c("accession", "position"),
                           relationship = "many-to-many") |>
    mutate(across(c(category, feature_type), ~ ifelse(is.na(.), "Unannotated", .)),
           across(c(category, feature_type), ~ str_replace(., "^(.)", toupper)))
  return(attn_expand)
}

attn_raw_mean  <- addFeatures(attn_raw_mean)
attn_raw_q90   <- addFeatures(attn_raw_q90)
attn_norm_mean <- addFeatures(attn_norm_mean)
attn_norm_q90  <- addFeatures(attn_norm_q90)
```

In general, the attention signal is highly noisy. Thus, we must apply smoothing to be able to make sense of it.

```{r}
nearestUneven <- function(x) {
  result <- sapply(x, function(val) {
    if (val %% 1 != 0) {
      val <- round(val)
    }
    if (val %% 2 == 0) {
      lower_odd <- val - 1
      upper_odd <- val + 1
      if (abs(val - lower_odd) <= abs(val - upper_odd)) {
        return(lower_odd)
      } else {
        return(upper_odd)
      }
    }
    return(val)
  })
  
  return(result)
}

gaussianKernel <- function(window, sigma){
  # Generate a symmetric sequence around 0.
  x <- seq(-(window-1)/2, (window-1)/2, by = 1)
  # Calculate the Gaussian distribution.
  kernel <- exp(-x^2 / (2 * sigma^2))
  # Normalize the kernel so that it sums to 1.
  kernel <- kernel / sum(kernel)
  
  return(kernel)
}

smoothAttention <- function(attention, method = "gaussian", window = 11, sigma = 5){
  # Check input.
  if (sum(method == c("mean", "gaussian")) != 1){
    stop("Error: Method is not valid. Choose 'mean', 'gaussian' or 'exact'.")
  }
  
  if (window %% 2 == 0){
    stop("Error: Window must be an uneven number.")
  }
  
  length <- length(attention)
  size <- (window-1)/2
  
  # Padding of edges.
  attention_pad <- c(rep(attention[1], size),
                     attention,
                     rep(attention[length], size))
    
  # Apply filter: Moving average.
  if (method == "mean"){
    attention_smooth <- stats::filter(attention_pad,
                                      rep(1/window, window),
                                      sides = 2) |>
      as.numeric()
    }
  
  # Apply filter: Gaussian kernel.
  if (method == "gaussian"){
    kernel <- gaussianKernel(window, sigma)
    attention_smooth <- stats::filter(attention_pad,
                                      kernel,
                                      sides = 2)
    }
    
  # Remove the padding.
  attention_smooth <- attention_smooth[(size+1):(size+length)]
  
  return(attention_smooth)
}
```

To summarize the attention, I average the attention weights for each position within a given feature type across layers. 

```{r}
plotHeatmap <- function(data, discrete = TRUE){
  
  # Summarize the data.
  data_summarized <- data |>
    mutate(W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S))) |>
    ungroup() |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(layer, feature_type) |>
    summarise(mean_attn = mean(bio_attn_Z_smooted),
              .groups = "drop")
  
  # Select unannotated to compare.
  data_unannotated <- data_summarized |>
    filter(feature_type == "Unannotated") |>
    select(layer, unannotated_attn = mean_attn)
  
  # Color the average attention only when above unannotated attention.
  if (discrete == TRUE){
    data_summarized <- left_join(data_summarized,
                                 data_unannotated,
                                 by = "layer") |>
      mutate(condition = case_when(mean_attn > unannotated_attn ~ "> Unannotated",
                                   .default = "< Unannotated"),
             condition = factor(condition)) |>
      filter(feature_type != "Unannotated")
    
     p_heat <- ggplot(data_summarized,
                     mapping = aes(x = layer, 
                                   y = feature_type, 
                                   fill = condition)) +
       geom_tile(color = "black") +
       scale_fill_manual(values = c("white", "#1f618d")) +
       scale_x_continuous(breaks = seq(1, 33, by = 2),
                         expand = c(0, 0)) + 
      scale_y_discrete(expand = c(0, 0)) +
      labs(x = "Layer",
           y = "Feature Type",
           fill = "Condition") +
      theme_classic()
  } else {
    # Color as scale. 
    p_heat <- ggplot(data_summarized,
                     mapping = aes(x = layer, 
                                   y = feature_type, 
                                   fill = mean_attn)) +
      geom_tile(color = "black") +
      scale_fill_gradient(low = "white", high = "#1f618d") + 
      scale_x_continuous(breaks = seq(1, 33, by = 2),
                         expand = c(0, 0)) + 
      scale_y_discrete(expand = c(0, 0)) +
      labs(x = "Layer",
           y = "Feature Type",
           fill = "Mean Attention") +
      theme_classic()
  }
  
  return(p_heat)
}
```

We look at the pattern for the attention weights aggregated by taken the average. 

```{r}
plotHeatmap(attn_raw_mean, discrete = FALSE) 
```

We see a trend, but this trend also accounts for unannotated positions. We color the tiles, but only if they exceed the average attention for unannotated areas.

```{r}
plotHeatmap(attn_raw_mean, discrete = TRUE) 
```

We look at the pattern for the attention weights aggregated by taken the 90% quantile.

```{r}
plotHeatmap(attn_raw_q90, discrete = FALSE) 
```

```{r}
plotHeatmap(attn_raw_q90, discrete = TRUE) 
```

We look at the mean attention in a slightly different way. 

```{r}
plotPath <- function(data){
  p_path <- data |>
    mutate(W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S))) |>
    ungroup() |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(layer, feature_type) |>
    summarise(mean_attn = mean(bio_attn_Z_smooted),
              .groups = "drop") |>
    ggplot(mapping = aes(x = layer,
                       y = mean_attn)) +
    geom_path(color = "#1f618d") +
    labs(x = "Layer",
           y = "Feature Type") + 
    theme_classic() + 
    facet_wrap(~ feature_type, ncol = 4)
  
  return(p_path)
}

plotPath(attn_raw_mean)
```
```{r}
plotPath(attn_raw_q90)
```

## Visualize examples

Above, I only considered the raw attention weights. When using the normalized weights, we force the scramble sequences to have more signal than they actually have because the softmax will put all weights between 0 and 1 summing to 1 per row. This will make the true biological signal vanish when comparing to the baseline. As a results, biological interesting region might not be detected. 

We define a function to plot the attention signal with features for a given sequences within a given layer. 

```{r}
plotExample <- function(data_attn, data_feature, acc, L){
  
  # Define region intervals.
  region <- data_feature |>
    filter(accession == acc)
  
  # Extract single sites from regions.
  site <- region |>
    filter(start_position == end_position)
  
  # Exclude sites from regions.
  region <- region |>
    filter(start_position != end_position) |>
    mutate(y_position = as.integer(factor(feature_type))) 
  
  # Define y position for site.
  site <- site |>
    mutate(y_position = max(region$y_position) + 1) 
  
  # Get the attention signal and apply smoothing.
  attn <- data_attn |>
    filter(accession == acc) |>
           #layer == L) |>
    mutate(W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S))) |>
    ungroup() #|>
    #group_by(accession, position) |>
    #mutate(bio_attn_Z_smooted = sum(abs(bio_attn_Z_smooted)))
  
  # Define the length of the sequence.
  seq_length <- max(attn$position)
  
  # Make background line.
  background_line <- tibble(start_position = 1,
                            end_position = seq_length,
                            y_position = c(unique(region$y_position),
                                           unique(site$y_position)))
  
  # Plot the features.
  p_features <- ggplot(region,
                       mapping = aes(x = start_position)) +
    geom_rect(background_line,
              mapping = aes(xmin = start_position,
                            xmax = end_position,
                            ymin = y_position - 0.02,
                            ymax = y_position + 0.02),
              color = "#E6E6E6") + 
    geom_rect(mapping = aes(xmin = start_position, 
                            xmax = end_position, 
                            ymin = y_position - 0.2, 
                            ymax = y_position + 0.2, 
                            fill = feature_type),
              alpha = 1, 
              color = "black") +
    geom_point(site,
               mapping = aes(x = start_position,
                             y = y_position),
               shape = 19,
               size = 3,
               color = "black") + 
    geom_point(site,
               mapping = aes(x = start_position,
                             y = y_position,
                             color = feature_type),
               shape = 20,
               size = 3) +
    scale_x_continuous(breaks = c(1, seq(50, seq_length-30, by = 50), seq_length),
                       limits = c(1, seq_length),
                       expand = expansion(mult = c(0.04, 0.04))) +
    scale_y_continuous(breaks = unique(region$y_position), 
                       labels = unique(region$feature_type)) +
    labs(x = "Position", 
         y = "", 
         color = "Site Type",
         fill = "Region Type") +
    theme_bw() +
    theme(legend.position = "left",
          axis.text.y = element_blank(), 
          axis.ticks.y = element_blank())
  
  # Add attention.
  p_attn <- ggplot(data = attn,
                   mapping = aes(x = position,
                                 y = bio_attn_Z_smooted,
                                 group = layer,
                                 color = layer)) +
    geom_path() + 
    geom_hline(yintercept = 0,
               color = "red") +
    scale_x_continuous(breaks = c(1, seq(50, seq_length-30, by = 50), seq_length),
                       limits = c(1, seq_length),
                       expand = expansion(mult = c(0.04, 0.04))) + 
    labs(x = "", 
         y = "Attention Score",
         color = "Layer",
         title = acc) +
    theme_bw() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  
  p_attn / p_features + plot_layout(guides = "collect")
}
```

We sample an example

```{r}
ex <- sample(accessions, size = 1)
print(ex)
```

Let's visualize this sequence.

```{r}
plotExample(attn_raw_mean, features, ex, 33)
```

## Capturing Sites and Regions

We wish to see how large a proportion of sites and regions we can capture when extracting regions with a high attention signal across layers. First, we will just consider each position as an observation in itself. 

```{r}
plotCapPos <- function(attn, threshold){
  p_cap_pos <- attn |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type)),
           W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z,
                                                window = unique(W),
                                                sigma = unique(S))) |>
    ungroup() |>
    mutate(high = case_when(bio_attn_Z_smooted > threshold ~ 1,
                            .default = 0)) |>
    group_by(layer, feature_type) |>
    summarise(detected = sum(high),
              total = n()) |>
    ungroup() |>
    mutate(proportion = detected/total) |>
    ggplot(mapping = aes(x = layer,
                         y = feature_type,
                         fill = proportion)) +
    geom_tile(color = "black") +
    scale_fill_gradient2(low = "#1f618d", mid = "white", high = "#990000", midpoint = 0.5) + 
    scale_x_continuous(breaks = seq(1, 33, by = 2),
                       expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) +
    labs(x = "Layer",
         y = "Feature Type",
         fill = "Proportion") +
    theme_classic() + 
    theme(legend.position = "bottom")
  
  p_cap_freq <- attn |>
    filter(layer == 1) |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(feature_type) |>
    summarise(total = n()) |>
    ggplot(mapping = aes(x = total,
                         y = feature_type)) +
    geom_bar(stat = "identity",
             fill = "black") +
    geom_text(mapping = aes(label = total),
              hjust = -0.15,
              size = 2.5) +
    scale_x_continuous(limits = c(0, 25000)) +
    scale_y_discrete(expand = c(0, 0)) + 
    theme_void()
  
  p_combined <- p_cap_pos + p_cap_freq
  
  return(p_combined)
}
```

In the plot below, a position is consider biological relevant, if the Z score is above 2. That is, the Z score is above 2 standard deviations. 

```{r}
plotCapPos(attn_raw_mean, 2)

ggsave(filename = paste(res_path, "cap_pos_mean_2sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

We consider a higher threshold.

```{r}
plotCapPos(attn_raw_mean, 3)

ggsave(filename = paste(res_path, "cap_pos_mean_3sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

```{r}
plotCapPos(attn_raw_q90, 3)

ggsave(filename = paste(res_path, "cap_pos_q90_3sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

```{r}
plotCapPos(attn_raw_q90, 4)

ggsave(filename = paste(res_path, "cap_pos_q90_4sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

Let's try to combine layers.

```{r}
plotCapPosComLay <- function(attn, threshold){
  p_cap_pos <- attn |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type)),
           W = nearestUneven(length/10),
           S = W/6,
           layer_group = case_when(layer %in% c(1,2,3) ~ 1,
                                   layer %in% c(4,5,6) ~ 2,
                                   layer %in% c(7,8,9) ~ 3,
                                   layer %in% c(10,11,12) ~ 4,
                                   layer %in% c(13,14,15) ~ 5,
                                   layer %in% c(16,17,18) ~ 6,
                                   layer %in% c(19,20,21) ~ 7,
                                   layer %in% c(22,23,24) ~ 8,
                                   layer %in% c(25,26,27) ~ 9,
                                   layer %in% c(28,29,30) ~ 10,
                                   layer %in% c(31,32,33) ~ 11)) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z,
                                                window = unique(W),
                                                sigma = unique(S))) |>
    ungroup() |>
    group_by(accession, position, layer_group) |>
    mutate(high = case_when(any(bio_attn_Z_smooted > threshold) ~ 1,
                            .default = 0)) |>
    group_by(layer_group, feature_type) |>
    summarise(detected = sum(high),
              total = n()) |>
    mutate(proportion = detected/total) |>
    ggplot(mapping = aes(x = layer_group,
                         y = feature_type,
                         fill = proportion)) +
    geom_tile(color = "black") +
    scale_fill_gradient2(low = "#1f618d", mid = "white", high = "#990000", midpoint = 0.5) + 
    scale_x_continuous(breaks = seq(1, 33, by = 2),
                       expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) +
    labs(x = "Layer",
         y = "Feature Type",
         fill = "Proportion") +
    theme_classic() + 
    theme(legend.position = "bottom")
  
  p_cap_freq <- attn |>
    filter(layer == 1) |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(feature_type) |>
    summarise(total = n()) |>
    ggplot(mapping = aes(x = total,
                         y = feature_type)) +
    geom_bar(stat = "identity",
             fill = "black") +
    geom_text(mapping = aes(label = total),
              hjust = -0.15,
              size = 2.5) +
    scale_x_continuous(limits = c(0, 25000)) +
    scale_y_discrete(expand = c(0, 0)) + 
    theme_void()
  
  p_combined <- p_cap_pos + p_cap_freq
  
  return(p_combined)
}
```

```{r}
plotCapPosComLay(attn_raw_mean, 3)

ggsave(filename = paste(res_path, "cap_pos_com_mean_3sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

```{r}
plotCapPosComLay(attn_raw_mean, 4)

ggsave(filename = paste(res_path, "cap_pos_com_mean_4sd.png", sep = ""), 
       width = 8, 
       height = 5)
```

```{r}
attn_raw_mean |>
  filter(layer %in% c(10:18, 28:33)) |>
  arrange(category, feature_type) |>
  mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type)),
          W = nearestUneven(length/10),
          S = W/6) |>
  group_by(accession, layer) |>
  mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z,
                                              window = unique(W),
                                              sigma = unique(S))) |>
  ungroup() |>
  group_by(accession, position) |>
  mutate(high = case_when(sum(bio_attn_Z_smooted) > 50 ~ 1,
                          .default = 0)) |>
  group_by(feature_type) |>
  summarise(detected = sum(high),
            total = n()) |>
  mutate(proportion = detected/total) |>
  ggplot(mapping = aes(x = feature_type,
                       y = proportion)) +
  geom_bar(stat = "identity",
           fill = "#1f618d") + 
  labs(x = "Annotation Type",
       y = "Proportion of captured positions") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## 

```{r}
region_extract <- attn_raw_mean |>
  arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type)),
           W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z,
                                                window = unique(W),
                                                sigma = unique(S))) |>
    ungroup() |>
    mutate(high = case_when(bio_attn_Z_smooted > 3 ~ 1,
                            .default = 0)) |>
  filter(high == 1)
```



```{r}
res <- c()

for (lay in 1:33){
  
  print(lay)
  
  anno_coverage <- list()
  
  for (acc in accessions){
    
    anno_data <- features |>
      filter(accession == acc)
    
    attn_data <- region_extract |>
      filter(accession == acc,
             layer == lay)
    
    # Get true annotation intervals (reduce to merge overlapping regions).
    true_ranges <- IRanges(start = anno_data$start_position,
                             end = anno_data$end_position)
    
    # Make the extracted attention positions into intervals.
    region_ranges <- IRanges(attn_data$position)
    
    # Find overlaps between annotated and attention regions.
    overlaps <- findOverlaps(true_ranges, region_ranges)
    
    # Define overlapping intervals.
    overlaps_intervals <- pintersect(true_ranges[queryHits(overlaps)],
                                     region_ranges[subjectHits(overlaps)])
    
    # Split ranges by the original true_ranges index
    split_overlaps <- split(overlaps_intervals , queryHits(overlaps))

    # Reduce each group to merge overlapping positions.
    reduced <- reduce(split_overlaps)

    # Sum the width of reduced overlaps.
    coverage <- numeric(length(true_ranges))
    coverage[as.integer(names(reduced))] <- sum(width(reduced))

    # Normalize by true range widths
    true_width <- width(true_ranges)
    coverage <- coverage / true_width
    
    # Save the results together with the sequence.
    result <- anno_data |>
      select(accession, category, feature_type) |>
      mutate(layer = lay,
             coverage = coverage)
    
    anno_coverage[[acc]] <- result
  }
  
  res <- rbind(res, bind_rows(anno_coverage))
}



```



```{r}
res |>
  arrange(category, feature_type) |>
  mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type)),
         detected = case_when(coverage > 0.5 ~ 1,
                              .default = 0)) |>
  group_by(layer, feature_type) |>
  summarise(detected = sum(detected),
            total = n()) |>
  mutate(proportion = detected/total) |>
  ggplot(mapping = aes(x = layer,
                         y = feature_type,
                         fill = proportion)) +
    geom_tile(color = "black") +
    scale_fill_gradient2(low = "#1f618d", mid = "white", high = "#990000", midpoint = 0.5) + 
    scale_x_continuous(breaks = seq(1, 33, by = 2),
                       expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) +
    labs(x = "Layer",
         y = "Feature Type",
         fill = "Proportion") +
    theme_classic() + 
    theme(legend.position = "bottom") +
  res |>
    filter(layer == 1) |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(feature_type) |>
    summarise(total = n()) |>
    ggplot(mapping = aes(x = total,
                         y = feature_type)) +
    geom_bar(stat = "identity",
             fill = "black") +
    geom_text(mapping = aes(label = total),
              hjust = -0.15,
              size = 2.5) +
    #scale_x_continuous(limits = c(0, 25000)) +
    scale_y_discrete(expand = c(0, 0)) + 
    theme_void()
```
























