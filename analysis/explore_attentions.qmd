---
title: "Exploratory Attention Analysis"
format: html
editor: visual
---

```{r, echo=FALSE, message=FALSE}
rm(list = ls())

library(tidyr)
library(purrr)
library(patchwork)
library(IRanges)

source("utils/smoothing.R")
source("utils/theme.R")
```

In this script, I will explore the behavior of the attention scores from the ESM-2 model.

## Why use raw attention scores?

I ran the ESM-2 model for 100 sequences and extracted the raw and normalized attention scores for each self-attention layer. I extract the raw attention scores, because we would otherwise force unannotated positions to have the same degree of signal as the annotated positions when applying the softmax. The heads within each layer was summarized by two methods: 1) by taken the average across heads and 2) computing the 90th quantile across heads. To compare the biological signal with a baseline, I also ran the model for 5 scramble sequences per biological sequence. The attention scores have been aggregated into vectors by taken the col mean to obtain an attention score per position. For the scrambled sequences, I summarize the results by computing the mean, standard deviation, minimum and maximum attention per position across the 5 sequences. Let's read in the data as well as the annotations. Besides normalizing from scrambled sequences, I will also apply a min-max normalization function.

```{r}
res_path <- here("reports/figures")

anno <- readRDS(file = file.path(here("data/complete/annotations/processed/anno.rds")))

# Expand annotations
anno_expanded <- anno |>
  rowwise() |>
  mutate(position = list(seq(start_position, end_position))) |>
  unnest(position) |>
  select(accession, position, category, feature_type)

# Define the min-max normalization function
minMaxNormalize <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# A helper function to load and process a single file
process_attn_file <- function(path, head_sum, attn_type) {
  readRDS(path) %>%
    mutate(head_sum = head_sum,
           attn_type = attn_type) |>
    select(accession, layer, position, bio_attn, bio_attn_Z, head_sum, attn_type) |>
    left_join(anno_expanded,
            by = c("accession", "position"),
            relationship = "many-to-many") |>
    mutate(across(c(category, feature_type), ~ ifelse(is.na(.), "unannotated", .)))
}

# Define all files and their metadata
files_info <- tribble(
  ~path, ~head_sum, ~attn_type,
  here("data/subset_00100/esm_processed/attn_raw_head_mean.rds"), "mean",   "raw",
  here("data/subset_00100/esm_processed/attn_raw_head_quan90.rds"), "quan90", "raw",
)

# Process and combine all into one data frame
all_attn <- pmap_dfr(files_info, process_attn_file)
```

For now, we do not consider the annotation type. We will just distinguish between annotated vs. unannotated positions. 

```{r}
all_attn <- all_attn |>
  mutate(annotated = case_when(feature_type == "unannotated" ~ "No",
                               .default = "Yes")) |>
  distinct()
```

We look at the distribution of the attention for unannotated and annotated positions.

```{r}
all_attn  |>
  #group_by(layer, head_sum, attn_type, annotated) |>
  #summarise(med = median(bio_attn)) |>
  ungroup() |>
  ggplot(mapping = aes(y = bio_attn_Z,
                       x = annotated,
                       color = annotated)) +
  geom_violin(alpha = 0.6, fill ="#1f618d") +
  geom_boxplot(width = 0.2) +
  #geom_line() + 
  main_theme +
  labs(y = "Attention Score") +
  facet_grid(rows = vars(attn_type),
             cols = vars(head_sum),
             scales = "free")
  #geom_violin(alpha = 0.6, width = 10) + 
  #geom_boxplot(width = 0.2)
            #Â´    fill = "grey80",
            #   outlier.shape = 1,
            #   outlier.color = scales::alpha("black", 0.4))

#ggsave(filename = file.path(res_path, "dist.png"), width = 4, height = 4, dpi = 300)
```

```{r}
data <- all_attn  |>
  select(-bio_attn, -bio_attn_minMax) |>
  pivot_wider(names_from = layer,
              names_prefix = "layer",
              values_from = bio_attn_Z) |>
  filter(head_sum == "quan90", attn_type == "raw")

# Select only numeric columns
numeric_data <- data |>
  select(where(is.numeric)) |>
  select(-position)

# Run PCA
pca_result <- prcomp(numeric_data, center = TRUE, scale. = TRUE)


df_pca <- bind_cols(
  data |> select(feature_type),
  as_tibble(pca_result$x)
)

ggplot(df_pca, aes(x = PC1, y = PC4, color = feature_type)) +
  geom_point()
```



## Distribution of Attention Weights

We look at the distribution between the attention weights after aggregating to 1D. We will compare the attentions for the biological sequence with the baseline, that is, the mean attention across the 5 scrambled sequences.

```{r}
plotDistAttention <- function(attn, title){
  plot <- attn |>
    select(bio_attn, scr_attn_mean) |>
    pivot_longer(cols = bio_attn:scr_attn_mean,
                 names_to = "attn_type",
                 values_to = "attn") |>
    mutate(attn_type = case_when(attn_type == "bio_attn" ~ "Biological signal",
                                 attn_type == "scr_attn_mean" ~ "Baseline signal")) |>
    ggplot(mapping = aes(x = attn_type,
                         y = attn,
                         fill = attn_type)) +
    geom_violin(alpha = 0.6) +
    geom_boxplot(width = 0.2,
                 fill = "grey80",
                 outlier.shape = 1,
                 outlier.color = scales::alpha("black", 0.4)) + 
    theme_classic() + 
    theme(legend.position = "none",
          plot.title = element_text(size = 12),
          panel.grid.major.y = element_line(color = "grey80"),
          axis.ticks.x = element_blank()) + 
    labs(x = "",
         y = "Attention",
         title = title) + 
    scale_fill_manual(values = c("#1f618d", "#1f618d"))
  
  return(plot)
}

plotDistAttention(attn_raw_mean, "Attention: Raw, Aggregation: Mean") +
plotDistAttention(attn_raw_q90, "Attention: Raw, Aggregation: Q90") +
  plot_layout(guides = "collect")
```

There seems to be a bigger difference between the distributions for the attention scores after aggregating using the 90% quantile.

The table also contains a Z-score for the attention signal (bio_attn_Z). The Z-score is a normalized biological signal calculated per position by subtracting the mean of the attention across the 5 scrambled sequences divided by the standard deviation.

$$Z = \frac{A_{bio}-A_{\mu_{scr}}}{A_{\sigma_{scr}}}$$

The purpose of this normalization is to center the signal around 0.

```{r}
plotDistBioZ <- function(attn, title){
  plot <- attn |>
    select(bio_attn_Z) |>
    ggplot(mapping = aes(y = bio_attn_Z)) +
    geom_boxplot(fill = "grey80",
                 outlier.shape = 1,
                 outlier.color = scales::alpha("black", 0.4)) + 
    theme_classic() + 
    theme(legend.position = "none",
          plot.title = element_text(size = 12),
          panel.grid.major.y = element_line(color = "grey80"),
          axis.ticks.x = element_blank()) + 
    labs(x = "",
         y = "Attention",
         title = title)
  
  return(plot)
}

plotDistBioZ(attn_raw_mean, "Attention: Raw, Aggregation: Mean") +
plotDistBioZ(attn_raw_q90, "Attention: Raw, Aggregation: Q90")
```

## Attention Across Layers and Annotation Types

We want to look at the attention for each feature type across the different layers. I load the annotations also denoted as features.



We join the annotations and lengths with the preprocessed attention weights.


In general, the attention signal is highly noisy. Thus, we must apply smoothing to be able to make sense of it.

```{r}
nearestUneven <- function(x) {
  result <- sapply(x, function(val) {
    if (val %% 1 != 0) {
      val <- round(val)
    }
    if (val %% 2 == 0) {
      lower_odd <- val - 1
      upper_odd <- val + 1
      if (abs(val - lower_odd) <= abs(val - upper_odd)) {
        return(lower_odd)
      } else {
        return(upper_odd)
      }
    }
    return(val)
  })
  
  return(result)
}

gaussianKernel <- function(window, sigma){
  # Generate a symmetric sequence around 0.
  x <- seq(-(window-1)/2, (window-1)/2, by = 1)
  # Calculate the Gaussian distribution.
  kernel <- exp(-x^2 / (2 * sigma^2))
  # Normalize the kernel so that it sums to 1.
  kernel <- kernel / sum(kernel)
  
  return(kernel)
}

smoothAttention <- function(attention, method = "gaussian", window = 11, sigma = 5){
  # Check input.
  if (sum(method == c("mean", "gaussian")) != 1){
    stop("Error: Method is not valid. Choose 'mean', 'gaussian' or 'exact'.")
  }
  
  if (window %% 2 == 0){
    stop("Error: Window must be an uneven number.")
  }
  
  length <- length(attention)
  size <- (window-1)/2
  
  # Padding of edges.
  attention_pad <- c(rep(attention[1], size),
                     attention,
                     rep(attention[length], size))
    
  # Apply filter: Moving average.
  if (method == "mean"){
    attention_smooth <- stats::filter(attention_pad,
                                      rep(1/window, window),
                                      sides = 2) |>
      as.numeric()
    }
  
  # Apply filter: Gaussian kernel.
  if (method == "gaussian"){
    kernel <- gaussianKernel(window, sigma)
    attention_smooth <- stats::filter(attention_pad,
                                      kernel,
                                      sides = 2)
    }
    
  # Remove the padding.
  attention_smooth <- attention_smooth[(size+1):(size+length)]
  
  return(attention_smooth)
}
```

To summarize the attention, I average the attention weights for each position within a given feature type across layers.

```{r}
plotHeatmap <- function(data, discrete = TRUE){
  
  # Summarize the data.
  data_summarized <- data |>
    mutate(W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S))) |>
    ungroup() |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(layer, feature_type) |>
    summarise(mean_attn = mean(bio_attn_Z_smooted),
              .groups = "drop")
  
  # Select unannotated to compare.
  data_unannotated <- data_summarized |>
    filter(feature_type == "Unannotated") |>
    select(layer, unannotated_attn = mean_attn)
  
  # Color the average attention only when above unannotated attention.
  if (discrete == TRUE){
    data_summarized <- left_join(data_summarized,
                                 data_unannotated,
                                 by = "layer") |>
      mutate(condition = case_when(mean_attn > unannotated_attn ~ "> Unannotated",
                                   .default = "< Unannotated"),
             condition = factor(condition)) |>
      filter(feature_type != "Unannotated")
    
     p_heat <- ggplot(data_summarized,
                     mapping = aes(x = layer, 
                                   y = feature_type, 
                                   fill = condition)) +
       geom_tile(color = "black") +
       scale_fill_manual(values = c("white", "#1f618d")) +
       scale_x_continuous(breaks = seq(1, 33, by = 2),
                         expand = c(0, 0)) + 
      scale_y_discrete(expand = c(0, 0)) +
      labs(x = "Layer",
           y = "Feature Type",
           fill = "Condition") +
      theme_classic()
  } else {
    # Color as scale. 
    p_heat <- ggplot(data_summarized,
                     mapping = aes(x = layer, 
                                   y = feature_type, 
                                   fill = mean_attn)) +
      geom_tile(color = "black") +
      scale_fill_gradient(low = "white", high = "#1f618d") + 
      scale_x_continuous(breaks = seq(1, 33, by = 2),
                         expand = c(0, 0)) + 
      scale_y_discrete(expand = c(0, 0)) +
      labs(x = "Layer",
           y = "Feature Type",
           fill = "Mean Attention") +
      theme_classic()
  }
  
  return(p_heat)
}
```

We look at the pattern for the attention weights aggregated by taken the average.

```{r}
plotHeatmap(attn_raw_mean, discrete = FALSE) 
```

We see a trend, but this trend also accounts for unannotated positions. We color the tiles, but only if they exceed the average attention for unannotated areas.

```{r}
plotHeatmap(attn_raw_mean, discrete = TRUE) 
```

We look at the pattern for the attention weights aggregated by taken the 90% quantile.

```{r}
plotHeatmap(attn_raw_q90, discrete = FALSE) 
```

```{r}
plotHeatmap(attn_raw_q90, discrete = TRUE) 
```

We look at the mean attention in a slightly different way.

```{r}
plotPath <- function(data){
  p_path <- data |>
    mutate(W = nearestUneven(length/10),
           S = W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S))) |>
    ungroup() |>
    arrange(category, feature_type) |>
    mutate(feature_type = factor(feature_type,
                                 levels = unique(feature_type))) |>
    group_by(layer, feature_type) |>
    summarise(mean_attn = mean(bio_attn_Z_smooted),
              .groups = "drop") |>
    ggplot(mapping = aes(x = layer,
                       y = mean_attn)) +
    geom_path(color = "#1f618d") +
    labs(x = "Layer",
           y = "Feature Type") + 
    theme_classic() + 
    facet_wrap(~ feature_type, ncol = 4)
  
  return(p_path)
}

plotPath(attn_raw_mean)
```

```{r}
plotPath(attn_raw_q90)
```

## Visualize examples

Above, I only considered the raw attention weights. When using the normalized weights, we force the scramble sequences to have more signal than they actually have because the softmax will put all weights between 0 and 1 summing to 1 per row. This will make the true biological signal vanish when comparing to the baseline. As a results, biological interesting region might not be detected.

We define a function to plot the attention signal with features for a given sequences within a given layer.

```{r}
plotExample <- function(data_attn, data_feature, acc, L){
  
  # Define region intervals.
  region <- data_feature |>
    filter(accession == acc)
  
  # Extract single sites from regions.
  site <- region |>
    filter(start_position == end_position)
  
  # Exclude sites from regions.
  region <- region |>
    filter(start_position != end_position) |>
    mutate(y_position = as.integer(factor(feature_type))) 
  
  # Define y position for site.
  site <- site |>
    mutate(y_position = max(region$y_position) + 1) 
  
  # Get the attention signal and apply smoothing.
  attn <- data_attn |>
    filter(accession == acc) |>
    mutate(W = 7,#nearestUneven(length/10),
           S = 1) |> #W/6) |>
    group_by(accession, layer) |>
    mutate(bio_attn_Z_smooted = smoothAttention(bio_attn_Z, 
                                                window = unique(W), 
                                                sigma = unique(S)),
           bio_attn_smooted = smoothAttention(bio_attn_minMax, 
                                              window = unique(W), 
                                              sigma = unique(S))) |>
    ungroup() |>
    mutate(layer_group = case_when(layer < 12 ~ "Layer 1:11",
                                   layer > 22 ~ "Layer 23:33",
                                   .default = "Layer 12:22"))
  
  # Define the length of the sequence.
  seq_length <- max(attn$position)
  
  # Make background line.
  background_line <- tibble(start_position = 1,
                            end_position = seq_length,
                            y_position = c(unique(region$y_position),
                                           unique(site$y_position)))
  
  # Plot the features.
  p_features <- ggplot(region,
                       mapping = aes(x = start_position)) +
    geom_rect(background_line,
              mapping = aes(xmin = start_position,
                            xmax = end_position,
                            ymin = y_position - 0.02,
                            ymax = y_position + 0.02),
              color = "#E6E6E6") + 
    geom_rect(mapping = aes(xmin = start_position, 
                            xmax = end_position, 
                            ymin = y_position - 0.2, 
                            ymax = y_position + 0.2, 
                            fill = feature_type),
              alpha = 1, 
              color = "black") +
    geom_point(site,
               mapping = aes(x = start_position,
                             y = y_position),
               shape = 19,
               size = 3,
               color = "black") + 
    geom_point(site,
               mapping = aes(x = start_position,
                             y = y_position,
                             color = feature_type),
               shape = 20,
               size = 3) +
    scale_x_continuous(breaks = c(1, seq(50, seq_length-30, by = 50), seq_length),
                       limits = c(1, seq_length),
                       expand = expansion(mult = c(0.04, 0.04))) +
    scale_y_continuous(breaks = unique(region$y_position), 
                       labels = unique(region$feature_type)) +
    labs(x = "Position", 
         y = "", 
         color = "Site Type",
         fill = "Region Type") +
    theme_bw() +
    theme(legend.position = "left",
          axis.text.y = element_blank(), 
          axis.ticks.y = element_blank())
  
  # Add attention.
  p_attn <- ggplot(data = attn,
                   mapping = aes(x = position,
                                 y = bio_attn_Z_smooted,
                                 group = layer,
                                 color = layer)) +
    geom_path() + 
    geom_hline(yintercept = 0,
               color = "red") +
    scale_x_continuous(breaks = c(1, seq(50, seq_length-30, by = 50), seq_length),
                       limits = c(1, seq_length),
                       expand = expansion(mult = c(0.04, 0.04))) + 
    #facet_grid(rows = vars(layer_group), scales = "free") +
    labs(x = "", 
         y = "Attention Score",
         color = "Layer",
         title = acc) +
    theme_bw() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  
  p_attn / p_features + plot_layout(guides = "collect")
}
```

We sample an example

```{r}
attn_ <- readRDS(here("data/subset_00100/esm_processed/attn_raw_head_mean.rds")) |>
  group_by(accession, layer) %>%
    mutate(bio_attn_minMax = minMaxNormalize(bio_attn)) %>%
    ungroup()

accessions <- unique(attn_$accession)
```


```{r}
ex <- sample(accessions, size = 1)
print(ex)
```

Let's visualize this sequence.

```{r}
plotExample(attn_, anno, ex, 33)

```












