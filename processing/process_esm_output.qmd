---
title: "ESM-2 Attention Preprocessing"
format: html
editor: visual
---

```{r, echo=FALSE, message=FALSE}
rm(list = ls())

library(tidyr)
library(dplyr)
library(ggplot2)
library(stringr)
library(jsonlite)
```

## Read ESM-2 output

We define functions to read in the ESM-2 output, here the attention weights.

```{r}
#------------------------------------------------------------------------------#

readJSON <- function(file_path){
  ### Read JSON - each batch is separated by newlines.
  
  data <- readLines(file_path) |>
    lapply(fromJSON) |>
    unlist(recursive=FALSE)
  
  return(data)
}

#------------------------------------------------------------------------------#

readAttnLayer <- function(layer, scr_num, esm_output_path, raw = TRUE){
  ### Read the attention for biological and scrambled sequences for a given
  ### layer.
  
  # Define correct file from input.
  layer <- str_pad(layer, width = 2, pad = "0")

  if (raw){
    format <- "raw"
  } 
  else {
    format <- "norm"
  }
  
  json_file_bio <- paste(esm_output_path, 
                         "biological_seq/attention/", 
                         format, 
                         "/layer_", 
                         layer, 
                         "_attn_",
                         format,
                         ".json", 
                         sep = "")

  # Get the attention from JSON file.
  attn_bio <- readJSON(json_file_bio)
  
  # Get the attention from scrambled sequences.
  attn_scr <- list()
  for (i in 1:scr_num){
    scr <- str_pad(i, width = 2, pad = "0")
    json_file_scr <- paste(esm_output_path, 
                           "scrambled_seq/scramble_", 
                           scr, 
                           "/attention/", 
                           format, 
                           "/layer_", 
                           layer, 
                           "_attn_",
                           format,
                           ".json",
                           sep = "")
    
    attn_scr[[i]] <- readJSON(json_file_scr)
  }
  
  # Transpose list.
  attn_scr <- lapply(1:length(attn_scr[[1]]), function(i) {
    # For each index i (from 1 to 100), extract the i-th element from each list
    lapply(attn_scr, function(inner_list) inner_list[[i]])})
  
  # Save result together.
  attn <- list(bio = attn_bio,
               scr = attn_scr)
  
  return(attn)
}

#------------------------------------------------------------------------------#

matrixToVector <- function(matrix_list, method = "mean"){
  ### Aggregate the matrices in list to vectors by either taking the row mean or 
  ### the 90% quantile per row. 
  
  # Mean method.
  if (method == "mean"){
    vector_list <- lapply(matrix_list, rowMeans)
  }
  # Quantile method.
  else if (method == "q90"){
    vector_list <- lapply(matrix_list, 
                          function(m){apply(m, 1, 
                                            function(row) quantile(row, probs = 0.9))})
  }
  # Check input.
  else {
    stop("Error: Invalid method. Supported: 'mean' or 'q90'.")
  }
  
  return(vector_list)
}

#------------------------------------------------------------------------------#

summarizeScrSignal <- function(scr_list){
### Summarize the scrambled signal after aggregating matrices into vectors.
  
  scr_summarized <- lapply(scr_list, function(list) {
    df <- as.data.frame(list)
    colnames(df) <- paste("scr_", 1:dim(df)[2], sep = "")
    df <- df |>
      mutate(position = as.numeric(rownames(df))) 
    df_sum <- df |>
      pivot_longer(cols = -position, 
                   names_to = "scramble", 
                   values_to = "scr_attn") |>
      group_by(position) |>
      summarise(scr_attn_mean = mean(scr_attn),
                scr_attn_sd = sd(scr_attn),
                scr_attn_min = min(scr_attn),
                scr_attn_max = max(scr_attn))
    df <- left_join(df_sum, df, by = "position")
    return(df)})
  
  return(scr_summarized)
}

#------------------------------------------------------------------------------#
```

For each layer, we will

-   Read the raw or normalized attention weights for the biological and scrambled sequences.

-   Aggregate the attention weights to get a 1D representations for the sequences by either computing the row means or 90% quantile.

-   Summarize the attention weights per position for the scramble sequences (mean, standard deviation, minimum and maximum).

-   Compute the Z-score for the biological per position attention ($$Z = \frac{A_{bio}-A_{\mu_{scr}}}{A_{\sigma_{scr}}}$$)

I build this pipeline as a function (`preprocesAttnLayer`).

```{r}
preprocesAttnLayer <- function(data_path, res_path, accessions, layers, method_attn, method_aggregate){
### Preprocess multiple attention layers with different methods.  
  
  # Decide weather to work with raw or normalized attention. 
   if (method_attn == "norm"){
     raw = FALSE
   } else {
     raw = TRUE
   }
  
  # A tibble to store the results.
  attn_all_layers <- tibble()
  
  # Extract the data.
  for (i in layers){
    
    layer <- i
    
    # Read the data for relevant layer.
    attn <- readAttnLayer(layer, 5, data_path, raw)
    
    # Convert biological attention. 
    attn_bio <- attn$bio |>
      matrixToVector(method_aggregate) |>
      lapply(function(matrix){
        df <- tibble(matrix)
        colnames(df) <- "bio_attn"
        df <- df |>
          mutate(position = as.numeric(rownames(df)))
        return(df)})
    
    # Add accession and layer info.
    attn_bio <- Map(function(bio, acc){
      df_acc <- bio |>
          mutate(accession = acc,
                 layer = layer) |>
        relocate(accession, layer, position)
        return(df_acc)
      }, attn_bio, accessions)
    
    # Modify and summarize the attention from scrambled sequences.
    attn_scr <- attn$scr |> 
      lapply(matrixToVector, method_aggregate) |>
      summarizeScrSignal()
    
    # Combine the biological and scramble attention weights.
    attn_combined <- Map(function(bio, scr){
      combined <- left_join(bio, scr, by = "position")
      return(combined)},
      attn_bio, attn_scr) |>
      bind_rows() |>
      mutate(bio_attn_Z = (bio_attn - scr_attn_mean) / scr_attn_sd) |>
      relocate(bio_attn_Z, .after = bio_attn)
    
    # Combine the results across layers.
    attn_all_layers <- bind_rows(attn_all_layers, attn_combined)
    
    print(paste("Layer", i, "done.", sep = " "))
  }

saveRDS(attn_all_layers, res_path)
}
```

I define the parameters, which will not change for the different runs.

```{r}
# Define data path.
data_path <- "/net/mimer/mnt/tank/projects2/kvs_students/2025/jbo_unbiased_seq_annot/master_thesis/data/100_small/esm_output/"

# Read the accessions.
accessions <- read.table(file = "data/100_small/additional/UP000005640_9606_sp_100_acc.txt") |>
  rename(accession = V1) |>
  select(accession) |>
  pull() |>
  c(function(x) x)

# Define layer range.
layers <- c(1:33)
```

I will start preprocessing raw attention weights and aggregate them to 1D using the mean method. Be aware: This takes more than 1.5 hours.

```{r}
preprocesAttnLayer(data_path, "data/100_small/preprocessed/attn_all_layers_raw_mean.rds", accessions, layers, method_attn = "raw", method_aggregate = "mean")
```

We repeat the steps but using the 90% quantile to aggregate into vectors. We will also preprocess the normalized attention weights.

```{r}
preprocesAttnLayer(data_path, "data/100_small/preprocessed/attn_all_layers_raw_q90.rds", accessions, layers, method_attn = "raw", method_aggregate = "q90")
preprocesAttnLayer(data_path, "data/100_small/preprocessed/attn_all_layers_norm_mean.rds", accessions, layers, method_attn = "norm", method_aggregate = "mean")
preprocesAttnLayer(data_path, "data/100_small/preprocessed/attn_all_layers_norm_q90.rds", accessions, layers, method_attn = "norm", method_aggregate = "q90")
```

```{r}
attn1 <- readAttnLayer(2, 5, data_path)
attn2 <- readAttnLayer(3, 5, data_path)

```



```{r}
attn_sum <- Map(function(attn1, attn2){
  attn1 + attn2
}, attn1$bio, attn2$bio)

attn1$bio[[1]][1:5,1:5]
attn2$bio[[1]][1:5,1:5]
attn_sum[[1]][1:5,1:5]

attn_average <- 
```


















